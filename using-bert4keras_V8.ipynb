{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f8ba58c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-01-25T13:45:50.140473Z",
     "iopub.status.busy": "2024-01-25T13:45:50.140042Z",
     "iopub.status.idle": "2024-01-25T13:45:50.157008Z",
     "shell.execute_reply": "2024-01-25T13:45:50.155520Z"
    },
    "papermill": {
     "duration": 0.026593,
     "end_time": "2024-01-25T13:45:50.160066",
     "exception": false,
     "start_time": "2024-01-25T13:45:50.133473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/pii-detection-removal-from-educational-data/sample_submission.csv\n",
      "/kaggle/input/pii-detection-removal-from-educational-data/train.json\n",
      "/kaggle/input/pii-detection-removal-from-educational-data/test.json\n",
      "/kaggle/input/google_bert/tensorflow2/bert_base_uncased_pii_43k_noblank/1/pii_gp_best_f1_0.92476.h5\n",
      "/kaggle/input/google_bert/tensorflow2/bert_base_uncased/1/bert_model.ckpt.index\n",
      "/kaggle/input/google_bert/tensorflow2/bert_base_uncased/1/bert_model.ckpt.meta\n",
      "/kaggle/input/google_bert/tensorflow2/bert_base_uncased/1/bert_config.json\n",
      "/kaggle/input/google_bert/tensorflow2/bert_base_uncased/1/vocab.txt\n",
      "/kaggle/input/google_bert/tensorflow2/bert_base_uncased/1/bert_model.ckpt.data-00000-of-00001\n",
      "/kaggle/input/bert4keras-packages/packs.tgz\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "#import numpy as np # linear algebra\n",
    "#import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78980404",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-25T13:45:50.173081Z",
     "iopub.status.busy": "2024-01-25T13:45:50.172820Z",
     "iopub.status.idle": "2024-01-25T13:45:58.051359Z",
     "shell.execute_reply": "2024-01-25T13:45:58.050229Z"
    },
    "papermill": {
     "duration": 7.886649,
     "end_time": "2024-01-25T13:45:58.053555",
     "exception": false,
     "start_time": "2024-01-25T13:45:50.166906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "packages/\r\n",
      "packages/Keras_Preprocessing-1.1.2-py2.py3-none-any.whl\r\n",
      "packages/tensorboard_plugin_wit-1.8.1-py3-none-any.whl\r\n",
      "packages/tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl\r\n",
      "packages/keras-2.8.0-py2.py3-none-any.whl\r\n",
      "packages/tensorflow-2.8.0-cp310-cp310-manylinux2010_x86_64.whl\r\n",
      "packages/tensorboard-2.8.0-py3-none-any.whl\r\n",
      "packages/tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl\r\n",
      "packages/bert4keras-0.11.5.tar.gz\r\n"
     ]
    }
   ],
   "source": [
    "!tar xvfz /kaggle/input/bert4keras-packages/packs.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eea7a32f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-25T13:45:58.065827Z",
     "iopub.status.busy": "2024-01-25T13:45:58.065498Z",
     "iopub.status.idle": "2024-01-25T13:46:41.765045Z",
     "shell.execute_reply": "2024-01-25T13:46:41.763103Z"
    },
    "papermill": {
     "duration": 43.709701,
     "end_time": "2024-01-25T13:46:41.768681",
     "exception": false,
     "start_time": "2024-01-25T13:45:58.058980",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: file:///kaggle/working/packages/\r\n",
      "Processing ./packages/bert4keras-0.11.5.tar.gz\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hBuilding wheels for collected packages: bert4keras\r\n",
      "  Building wheel for bert4keras (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for bert4keras: filename=bert4keras-0.11.5-py3-none-any.whl size=52070 sha256=613da1dfac097b5f0aaca97157351345f1a64856209ee465b3a74d169f64b273\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/68/52/56/1d8ef6ed93c22424276d7f9c61f8e50feb9fd279131fd111e9\r\n",
      "Successfully built bert4keras\r\n",
      "Installing collected packages: bert4keras\r\n",
      "Successfully installed bert4keras-0.11.5\r\n",
      "Looking in links: file:///kaggle/working/packages/\r\n",
      "Processing ./packages/tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl\r\n",
      "Processing ./packages/tensorboard-2.8.0-py3-none-any.whl\r\n",
      "Processing ./packages/Keras_Preprocessing-1.1.2-py2.py3-none-any.whl\r\n",
      "Processing ./packages/tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl\r\n",
      "Processing ./packages/tensorboard_plugin_wit-1.8.1-py3-none-any.whl\r\n",
      "Installing collected packages: tf_estimator_nightly, tensorboard_plugin_wit, Keras_Preprocessing, tensorboard_data_server, tensorboard\r\n",
      "  Attempting uninstall: tensorboard_data_server\r\n",
      "    Found existing installation: tensorboard-data-server 0.7.1\r\n",
      "    Uninstalling tensorboard-data-server-0.7.1:\r\n",
      "      Successfully uninstalled tensorboard-data-server-0.7.1\r\n",
      "  Attempting uninstall: tensorboard\r\n",
      "    Found existing installation: tensorboard 2.13.0\r\n",
      "    Uninstalling tensorboard-2.13.0:\r\n",
      "      Successfully uninstalled tensorboard-2.13.0\r\n",
      "Successfully installed Keras_Preprocessing-1.1.2 tensorboard-2.8.0 tensorboard_data_server-0.6.1 tensorboard_plugin_wit-1.8.1 tf_estimator_nightly-2.8.0.dev2021122109\r\n",
      "Looking in links: file:///kaggle/working/packages/\r\n",
      "Processing ./packages/tensorflow-2.8.0-cp310-cp310-manylinux2010_x86_64.whl\r\n",
      "Processing ./packages/keras-2.8.0-py2.py3-none-any.whl\r\n",
      "Installing collected packages: tensorflow, keras\r\n",
      "  Attempting uninstall: tensorflow\r\n",
      "    Found existing installation: tensorflow 2.13.0\r\n",
      "    Uninstalling tensorflow-2.13.0:\r\n",
      "      Successfully uninstalled tensorflow-2.13.0\r\n",
      "  Attempting uninstall: keras\r\n",
      "    Found existing installation: keras 2.13.1\r\n",
      "    Uninstalling keras-2.13.1:\r\n",
      "      Successfully uninstalled keras-2.13.1\r\n",
      "Successfully installed keras-2.8.0 tensorflow-2.8.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install bert4keras --no-deps --force --no-index --find-links=file:///kaggle/working/packages/\n",
    "!pip install tensorboard_data_server tensorboard Keras_Preprocessing tf_estimator_nightly tensorboard_plugin_wit --no-deps --force --no-index --find-links=file:///kaggle/working/packages/\n",
    "!pip install tensorflow keras --no-deps --force --no-index --find-links=file:///kaggle/working/packages/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deab0449",
   "metadata": {
    "papermill": {
     "duration": 0.0117,
     "end_time": "2024-01-25T13:46:41.794518",
     "exception": false,
     "start_time": "2024-01-25T13:46:41.782818",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Initial env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b66c7818",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-25T13:46:41.817282Z",
     "iopub.status.busy": "2024-01-25T13:46:41.816915Z",
     "iopub.status.idle": "2024-01-25T13:46:41.822427Z",
     "shell.execute_reply": "2024-01-25T13:46:41.820845Z"
    },
    "papermill": {
     "duration": 0.020752,
     "end_time": "2024-01-25T13:46:41.825820",
     "exception": false,
     "start_time": "2024-01-25T13:46:41.805068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install bert4keras --no-deps --force\n",
    "#!pip install tensorflow-gpu==2.8.0\n",
    "#!pip install tensorflow==2.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b65db407",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-25T13:46:41.846976Z",
     "iopub.status.busy": "2024-01-25T13:46:41.846613Z",
     "iopub.status.idle": "2024-01-25T13:46:47.761856Z",
     "shell.execute_reply": "2024-01-25T13:46:47.760727Z"
    },
    "papermill": {
     "duration": 5.92899,
     "end_time": "2024-01-25T13:46:47.764232",
     "exception": false,
     "start_time": "2024-01-25T13:46:41.835242",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp /opt/conda/lib/python3.10/site-packages/bert4keras/backend.py _b.py\n",
    "!sed -i \"18s/sys/#sys/\" _b.py\n",
    "!sed \"18a\\    from tensorflow import keras\\n    import tensorflow.keras.backend as K\" _b.py > _b2.py\n",
    "!sed -i \"22s/import/#import/\" _b2.py\n",
    "!sed -i \"23s/import/#import/\" _b2.py\n",
    "!cp _b2.py /opt/conda/lib/python3.10/site-packages/bert4keras/backend.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f433210a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-25T13:46:47.780939Z",
     "iopub.status.busy": "2024-01-25T13:46:47.780611Z",
     "iopub.status.idle": "2024-01-25T13:46:47.784949Z",
     "shell.execute_reply": "2024-01-25T13:46:47.784171Z"
    },
    "papermill": {
     "duration": 0.014731,
     "end_time": "2024-01-25T13:46:47.786837",
     "exception": false,
     "start_time": "2024-01-25T13:46:47.772106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!curl -LJO https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-12_H-768_A-12.zip\n",
    "#!unzip uncased_L-12_H-768_A-12.zip -d bert_base\n",
    "\n",
    "#!curl -LJO https://storage.googleapis.com/bert_models/2019_05_30/wwm_uncased_L-24_H-1024_A-16.zip\n",
    "#!unzip uncased_L-12_H-768_A-12.zip -d bert_large"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fdc161",
   "metadata": {
    "papermill": {
     "duration": 0.007306,
     "end_time": "2024-01-25T13:46:47.801502",
     "exception": false,
     "start_time": "2024-01-25T13:46:47.794196",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Convert raw data to train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d60e1c22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-25T13:46:47.818414Z",
     "iopub.status.busy": "2024-01-25T13:46:47.818128Z",
     "iopub.status.idle": "2024-01-25T13:46:47.862363Z",
     "shell.execute_reply": "2024-01-25T13:46:47.861692Z"
    },
    "papermill": {
     "duration": 0.055543,
     "end_time": "2024-01-25T13:46:47.864356",
     "exception": false,
     "start_time": "2024-01-25T13:46:47.808813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "\n",
    "train_file = '/kaggle/input/pii-detection-removal-from-educational-data/train.json'\n",
    "test_file = '/kaggle/input/pii-detection-removal-from-educational-data/test.json'\n",
    "\n",
    "split_ratio = 0.8\n",
    "\n",
    "\n",
    "def __convert(indata, include_blank=True):\n",
    "\n",
    "    text = ''\n",
    "    entities = []\n",
    "    all_idx = 0\n",
    "    start_idx = 0\n",
    "    etype = ''\n",
    "\n",
    "    text = indata['sentence']\n",
    "\n",
    "    for n, label in enumerate(indata['BIO_label']):\n",
    "        if label[0]=='O':\n",
    "            if etype!='':\n",
    "                entities.append({\n",
    "                    \"start_idx\": len(''.join(text[:start_idx])),\n",
    "                    \"end_idx\": len((''.join(text[:all_idx])).rstrip()) - 1,\n",
    "                    \"type\": etype,\n",
    "                    \"entity\": (''.join(text[start_idx:all_idx])).rstrip(),\n",
    "                })\n",
    "            start_idx = 0\n",
    "            etype = ''\n",
    "        elif label[0]=='B':\n",
    "            if etype!='':\n",
    "                entities.append({\n",
    "                    \"start_idx\": len(''.join(text[:start_idx])),\n",
    "                    \"end_idx\": len((''.join(text[:all_idx])).rstrip()) - 1,\n",
    "                    \"type\": etype,\n",
    "                    \"entity\": (''.join(text[start_idx:all_idx])).rstrip(),\n",
    "                })                \n",
    "            start_idx = all_idx\n",
    "            etype = label.split('-')[1]\n",
    "        elif label[0]=='I':\n",
    "            pass\n",
    "        else:\n",
    "            print('unknown label: ', label)\n",
    "\n",
    "        all_idx += 1\n",
    "\n",
    "\n",
    "    # 一行text结束\n",
    "    if etype!='':\n",
    "        entities.append({\n",
    "            \"start_idx\": len(''.join(text[:start_idx])),\n",
    "            \"end_idx\": len((''.join(text[:all_idx])).rstrip()) - 1,\n",
    "            \"type\": etype,\n",
    "            \"entity\": (''.join(text[start_idx:all_idx])).rstrip(),\n",
    "        })\n",
    "\n",
    "    # 加入数据集\n",
    "    if include_blank or len(entities)>0:\n",
    "        return {\n",
    "            'text' : ''.join(text),\n",
    "            'entities' : entities,\n",
    "        }\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def assemble(infile, outfile_path, max_len=500, is_train=True, include_blank=True):\n",
    "    total = text_break = tmp_break = 0\n",
    "    D = []\n",
    "\n",
    "    data = json.load(open(infile))\n",
    "    for l in tqdm(data):\n",
    "        #print(f\"---> {l['document']}\")\n",
    "\n",
    "        total += 1\n",
    "\n",
    "        text = []\n",
    "        tmp_text = []\n",
    "        n = n_text = n_tmp = 0\n",
    "        while n<len(l['tokens']):\n",
    "            token = l['tokens'][n]\n",
    "            if l['trailing_whitespace'][n]:\n",
    "                token += ' ' \n",
    "\n",
    "            if n_tmp + 1 > max_len:\n",
    "                text += deepcopy(tmp_text)\n",
    "                tmp_text = []\n",
    "                n_text += n_tmp\n",
    "                n_tmp = 0\n",
    "\n",
    "                tmp_break += 1\n",
    "\n",
    "                #print(text)\n",
    "                #assert False, f\"tmp_text is too long: {len(text)}, {len(tmp_text)}, {len(token)}\"\n",
    "\n",
    "            if n_text + n_tmp + 1 > max_len:\n",
    "                assert n_text>0, f\"too long: {n_text}, {n_tmp}, {max_len}\"\n",
    "                #print(text)\n",
    "                #print('-'*20)\n",
    "                dd = __convert({\n",
    "                        'sentence'  : [x[0] for x in text],\n",
    "                        'BIO_label' : [x[1] for x in text],\n",
    "                    }, include_blank=include_blank)\n",
    "                if dd:\n",
    "                    dd['document'] = l['document']\n",
    "                    if not is_train:\n",
    "                        dd['tokens'] = [x[0] for x in text]\n",
    "                    D.append(dd)\n",
    "                text = []\n",
    "                n_text = 0\n",
    "\n",
    "                text_break += 1\n",
    "\n",
    "            if is_train:\n",
    "                tmp_text += [(token, l['labels'][n])] # token, label\n",
    "            else:\n",
    "                tmp_text += [(token, 'O')] # token, blank-label\n",
    "            n_tmp += 1\n",
    "\n",
    "            if token=='\\n\\n':\n",
    "                text += deepcopy(tmp_text)\n",
    "                tmp_text = []\n",
    "                n_text += n_tmp\n",
    "                n_tmp = 0\n",
    "\n",
    "            n += 1\n",
    "\n",
    "        if n_text + n_tmp > 0:\n",
    "            text += deepcopy(tmp_text)\n",
    "            n_text += n_tmp\n",
    "            #print(text)\n",
    "            #print('-'*20)\n",
    "            dd = __convert({\n",
    "                    'sentence'  : [x[0] for x in text],\n",
    "                    'BIO_label' : [x[1] for x in text],\n",
    "                }, include_blank=include_blank)\n",
    "            if dd:\n",
    "                dd['document'] = l['document']\n",
    "                if not is_train:\n",
    "                    dd['tokens'] = [x[0] for x in text]\n",
    "                D.append(dd)\n",
    "\n",
    "            text_break += 1            \n",
    "\n",
    "        #break # for test\n",
    "\n",
    "    blank = 0\n",
    "    for x in D:\n",
    "        if len(x['entities'])==0:\n",
    "            blank += 1\n",
    "\n",
    "    print(f\"total= {total}\\ttext_break= {text_break}\\ttmp_break= {tmp_break}\\tblank= {blank}\")\n",
    "\n",
    "    if is_train:\n",
    "        random.shuffle(D)\n",
    "\n",
    "        # 拆分数据集\n",
    "        split_n = int(len(D) * split_ratio)\n",
    "\n",
    "        json.dump(\n",
    "            D[:split_n],\n",
    "            open(os.path.join(outfile_path, \"train.json\"), 'w', encoding='utf-8'),\n",
    "            indent=4,\n",
    "            ensure_ascii=False\n",
    "        )\n",
    "\n",
    "\n",
    "        json.dump(\n",
    "            D[split_n:],\n",
    "            open(os.path.join(outfile_path, \"dev.json\"), 'w', encoding='utf-8'),\n",
    "            indent=4,\n",
    "            ensure_ascii=False\n",
    "        )\n",
    "\n",
    "        print(f\"train set: {split_n}\\tdev set: {len(D)-split_n}\")\n",
    "\n",
    "    else:\n",
    "        json.dump(\n",
    "            D,\n",
    "            open(os.path.join(outfile_path, \"test.json\"), 'w', encoding='utf-8'),\n",
    "            indent=4,\n",
    "            ensure_ascii=False\n",
    "        )\n",
    "\n",
    "        print(f\"test set: {len(D)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e83e66d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-25T13:46:47.880627Z",
     "iopub.status.busy": "2024-01-25T13:46:47.880350Z",
     "iopub.status.idle": "2024-01-25T13:47:22.298808Z",
     "shell.execute_reply": "2024-01-25T13:47:22.297858Z"
    },
    "papermill": {
     "duration": 34.428707,
     "end_time": "2024-01-25T13:47:22.300789",
     "exception": false,
     "start_time": "2024-01-25T13:46:47.872082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6807/6807 [00:31<00:00, 216.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total= 6807\ttext_break= 14370\ttmp_break= 829\tblank= 0\n",
      "train set: 894\tdev set: 224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 188.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total= 10\ttext_break= 24\ttmp_break= 3\tblank= 24\n",
      "test set: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "assemble(train_file, '.', include_blank=False)\n",
    "assemble(test_file, '.', is_train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6096cc",
   "metadata": {
    "papermill": {
     "duration": 0.030226,
     "end_time": "2024-01-25T13:47:22.361718",
     "exception": false,
     "start_time": "2024-01-25T13:47:22.331492",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "322b3054",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-25T13:47:22.423236Z",
     "iopub.status.busy": "2024-01-25T13:47:22.422916Z",
     "iopub.status.idle": "2024-01-25T13:47:30.810436Z",
     "shell.execute_reply": "2024-01-25T13:47:30.809436Z"
    },
    "papermill": {
     "duration": 8.519154,
     "end_time": "2024-01-25T13:47:30.910866",
     "exception": false,
     "start_time": "2024-01-25T13:47:22.391712",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels:  ['EMAIL', 'ID_NUM', 'NAME_STUDENT', 'PHONE_NUM', 'STREET_ADDRESS', 'URL_PERSONAL', 'USERNAME']\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Input-Token (InputLayer)       [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " Input-Segment (InputLayer)     [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " Embedding-Token (Embedding)    (None, None, 768)    23440896    ['Input-Token[0][0]']            \n",
      "                                                                                                  \n",
      " Embedding-Segment (Embedding)  (None, None, 768)    1536        ['Input-Segment[0][0]']          \n",
      "                                                                                                  \n",
      " Embedding-Token-Segment (Add)  (None, None, 768)    0           ['Embedding-Token[0][0]',        \n",
      "                                                                  'Embedding-Segment[0][0]']      \n",
      "                                                                                                  \n",
      " Embedding-Position (PositionEm  (None, None, 768)   393216      ['Embedding-Token-Segment[0][0]']\n",
      " bedding)                                                                                         \n",
      "                                                                                                  \n",
      " Embedding-Norm (LayerNormaliza  (None, None, 768)   1536        ['Embedding-Position[0][0]']     \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " Embedding-Dropout (Dropout)    (None, None, 768)    0           ['Embedding-Norm[0][0]']         \n",
      "                                                                                                  \n",
      " Transformer-0-MultiHeadSelfAtt  (None, None, 768)   2362368     ['Embedding-Dropout[0][0]',      \n",
      " ention (MultiHeadAttention)                                      'Embedding-Dropout[0][0]',      \n",
      "                                                                  'Embedding-Dropout[0][0]']      \n",
      "                                                                                                  \n",
      " Transformer-0-MultiHeadSelfAtt  (None, None, 768)   0           ['Transformer-0-MultiHeadSelfAtte\n",
      " ention-Dropout (Dropout)                                        ntion[0][0]']                    \n",
      "                                                                                                  \n",
      " Transformer-0-MultiHeadSelfAtt  (None, None, 768)   0           ['Embedding-Dropout[0][0]',      \n",
      " ention-Add (Add)                                                 'Transformer-0-MultiHeadSelfAtte\n",
      "                                                                 ntion-Dropout[0][0]']            \n",
      "                                                                                                  \n",
      " Transformer-0-MultiHeadSelfAtt  (None, None, 768)   1536        ['Transformer-0-MultiHeadSelfAtte\n",
      " ention-Norm (LayerNormalizatio                                  ntion-Add[0][0]']                \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " Transformer-0-FeedForward (Fee  (None, None, 768)   4722432     ['Transformer-0-MultiHeadSelfAtte\n",
      " dForward)                                                       ntion-Norm[0][0]']               \n",
      "                                                                                                  \n",
      " Transformer-0-FeedForward-Drop  (None, None, 768)   0           ['Transformer-0-FeedForward[0][0]\n",
      " out (Dropout)                                                   ']                               \n",
      "                                                                                                  \n",
      " Transformer-0-FeedForward-Add   (None, None, 768)   0           ['Transformer-0-MultiHeadSelfAtte\n",
      " (Add)                                                           ntion-Norm[0][0]',               \n",
      "                                                                  'Transformer-0-FeedForward-Dropo\n",
      "                                                                 ut[0][0]']                       \n",
      "                                                                                                  \n",
      " Transformer-0-FeedForward-Norm  (None, None, 768)   1536        ['Transformer-0-FeedForward-Add[0\n",
      "  (LayerNormalization)                                           ][0]']                           \n",
      "                                                                                                  \n",
      " Transformer-1-MultiHeadSelfAtt  (None, None, 768)   2362368     ['Transformer-0-FeedForward-Norm[\n",
      " ention (MultiHeadAttention)                                     0][0]',                          \n",
      "                                                                  'Transformer-0-FeedForward-Norm[\n",
      "                                                                 0][0]',                          \n",
      "                                                                  'Transformer-0-FeedForward-Norm[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " Transformer-1-MultiHeadSelfAtt  (None, None, 768)   0           ['Transformer-1-MultiHeadSelfAtte\n",
      " ention-Dropout (Dropout)                                        ntion[0][0]']                    \n",
      "                                                                                                  \n",
      " Transformer-1-MultiHeadSelfAtt  (None, None, 768)   0           ['Transformer-0-FeedForward-Norm[\n",
      " ention-Add (Add)                                                0][0]',                          \n",
      "                                                                  'Transformer-1-MultiHeadSelfAtte\n",
      "                                                                 ntion-Dropout[0][0]']            \n",
      "                                                                                                  \n",
      " Transformer-1-MultiHeadSelfAtt  (None, None, 768)   1536        ['Transformer-1-MultiHeadSelfAtte\n",
      " ention-Norm (LayerNormalizatio                                  ntion-Add[0][0]']                \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " Transformer-1-FeedForward (Fee  (None, None, 768)   4722432     ['Transformer-1-MultiHeadSelfAtte\n",
      " dForward)                                                       ntion-Norm[0][0]']               \n",
      "                                                                                                  \n",
      " Transformer-1-FeedForward-Drop  (None, None, 768)   0           ['Transformer-1-FeedForward[0][0]\n",
      " out (Dropout)                                                   ']                               \n",
      "                                                                                                  \n",
      " Transformer-1-FeedForward-Add   (None, None, 768)   0           ['Transformer-1-MultiHeadSelfAtte\n",
      " (Add)                                                           ntion-Norm[0][0]',               \n",
      "                                                                  'Transformer-1-FeedForward-Dropo\n",
      "                                                                 ut[0][0]']                       \n",
      "                                                                                                  \n",
      " Transformer-1-FeedForward-Norm  (None, None, 768)   1536        ['Transformer-1-FeedForward-Add[0\n",
      "  (LayerNormalization)                                           ][0]']                           \n",
      "                                                                                                  \n",
      " Transformer-2-MultiHeadSelfAtt  (None, None, 768)   2362368     ['Transformer-1-FeedForward-Norm[\n",
      " ention (MultiHeadAttention)                                     0][0]',                          \n",
      "                                                                  'Transformer-1-FeedForward-Norm[\n",
      "                                                                 0][0]',                          \n",
      "                                                                  'Transformer-1-FeedForward-Norm[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " Transformer-2-MultiHeadSelfAtt  (None, None, 768)   0           ['Transformer-2-MultiHeadSelfAtte\n",
      " ention-Dropout (Dropout)                                        ntion[0][0]']                    \n",
      "                                                                                                  \n",
      " Transformer-2-MultiHeadSelfAtt  (None, None, 768)   0           ['Transformer-1-FeedForward-Norm[\n",
      " ention-Add (Add)                                                0][0]',                          \n",
      "                                                                  'Transformer-2-MultiHeadSelfAtte\n",
      "                                                                 ntion-Dropout[0][0]']            \n",
      "                                                                                                  \n",
      " Transformer-2-MultiHeadSelfAtt  (None, None, 768)   1536        ['Transformer-2-MultiHeadSelfAtte\n",
      " ention-Norm (LayerNormalizatio                                  ntion-Add[0][0]']                \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " Transformer-2-FeedForward (Fee  (None, None, 768)   4722432     ['Transformer-2-MultiHeadSelfAtte\n",
      " dForward)                                                       ntion-Norm[0][0]']               \n",
      "                                                                                                  \n",
      " Transformer-2-FeedForward-Drop  (None, None, 768)   0           ['Transformer-2-FeedForward[0][0]\n",
      " out (Dropout)                                                   ']                               \n",
      "                                                                                                  \n",
      " Transformer-2-FeedForward-Add   (None, None, 768)   0           ['Transformer-2-MultiHeadSelfAtte\n",
      " (Add)                                                           ntion-Norm[0][0]',               \n",
      "                                                                  'Transformer-2-FeedForward-Dropo\n",
      "                                                                 ut[0][0]']                       \n",
      "                                                                                                  \n",
      " Transformer-2-FeedForward-Norm  (None, None, 768)   1536        ['Transformer-2-FeedForward-Add[0\n",
      "  (LayerNormalization)                                           ][0]']                           \n",
      "                                                                                                  \n",
      " Transformer-3-MultiHeadSelfAtt  (None, None, 768)   2362368     ['Transformer-2-FeedForward-Norm[\n",
      " ention (MultiHeadAttention)                                     0][0]',                          \n",
      "                                                                  'Transformer-2-FeedForward-Norm[\n",
      "                                                                 0][0]',                          \n",
      "                                                                  'Transformer-2-FeedForward-Norm[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " Transformer-3-MultiHeadSelfAtt  (None, None, 768)   0           ['Transformer-3-MultiHeadSelfAtte\n",
      " ention-Dropout (Dropout)                                        ntion[0][0]']                    \n",
      "                                                                                                  \n",
      " Transformer-3-MultiHeadSelfAtt  (None, None, 768)   0           ['Transformer-2-FeedForward-Norm[\n",
      " ention-Add (Add)                                                0][0]',                          \n",
      "                                                                  'Transformer-3-MultiHeadSelfAtte\n",
      "                                                                 ntion-Dropout[0][0]']            \n",
      "                                                                                                  \n",
      " Transformer-3-MultiHeadSelfAtt  (None, None, 768)   1536        ['Transformer-3-MultiHeadSelfAtte\n",
      " ention-Norm (LayerNormalizatio                                  ntion-Add[0][0]']                \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " Transformer-3-FeedForward (Fee  (None, None, 768)   4722432     ['Transformer-3-MultiHeadSelfAtte\n",
      " dForward)                                                       ntion-Norm[0][0]']               \n",
      "                                                                                                  \n",
      " Transformer-3-FeedForward-Drop  (None, None, 768)   0           ['Transformer-3-FeedForward[0][0]\n",
      " out (Dropout)                                                   ']                               \n",
      "                                                                                                  \n",
      " Transformer-3-FeedForward-Add   (None, None, 768)   0           ['Transformer-3-MultiHeadSelfAtte\n",
      " (Add)                                                           ntion-Norm[0][0]',               \n",
      "                                                                  'Transformer-3-FeedForward-Dropo\n",
      "                                                                 ut[0][0]']                       \n",
      "                                                                                                  \n",
      " Transformer-3-FeedForward-Norm  (None, None, 768)   1536        ['Transformer-3-FeedForward-Add[0\n",
      "  (LayerNormalization)                                           ][0]']                           \n",
      "                                                                                                  \n",
      " Transformer-4-MultiHeadSelfAtt  (None, None, 768)   2362368     ['Transformer-3-FeedForward-Norm[\n",
      " ention (MultiHeadAttention)                                     0][0]',                          \n",
      "                                                                  'Transformer-3-FeedForward-Norm[\n",
      "                                                                 0][0]',                          \n",
      "                                                                  'Transformer-3-FeedForward-Norm[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " Transformer-4-MultiHeadSelfAtt  (None, None, 768)   0           ['Transformer-4-MultiHeadSelfAtte\n",
      " ention-Dropout (Dropout)                                        ntion[0][0]']                    \n",
      "                                                                                                  \n",
      " Transformer-4-MultiHeadSelfAtt  (None, None, 768)   0           ['Transformer-3-FeedForward-Norm[\n",
      " ention-Add (Add)                                                0][0]',                          \n",
      "                                                                  'Transformer-4-MultiHeadSelfAtte\n",
      "                                                                 ntion-Dropout[0][0]']            \n",
      "                                                                                                  \n",
      " Transformer-4-MultiHeadSelfAtt  (None, None, 768)   1536        ['Transformer-4-MultiHeadSelfAtte\n",
      " ention-Norm (LayerNormalizatio                                  ntion-Add[0][0]']                \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " Transformer-4-FeedForward (Fee  (None, None, 768)   4722432     ['Transformer-4-MultiHeadSelfAtte\n",
      " dForward)                                                       ntion-Norm[0][0]']               \n",
      "                                                                                                  \n",
      " Transformer-4-FeedForward-Drop  (None, None, 768)   0           ['Transformer-4-FeedForward[0][0]\n",
      " out (Dropout)                                                   ']                               \n",
      "                                                                                                  \n",
      " Transformer-4-FeedForward-Add   (None, None, 768)   0           ['Transformer-4-MultiHeadSelfAtte\n",
      " (Add)                                                           ntion-Norm[0][0]',               \n",
      "                                                                  'Transformer-4-FeedForward-Dropo\n",
      "                                                                 ut[0][0]']                       \n",
      "                                                                                                  \n",
      " Transformer-4-FeedForward-Norm  (None, None, 768)   1536        ['Transformer-4-FeedForward-Add[0\n",
      "  (LayerNormalization)                                           ][0]']                           \n",
      "                                                                                                  \n",
      " Transformer-5-MultiHeadSelfAtt  (None, None, 768)   2362368     ['Transformer-4-FeedForward-Norm[\n",
      " ention (MultiHeadAttention)                                     0][0]',                          \n",
      "                                                                  'Transformer-4-FeedForward-Norm[\n",
      "                                                                 0][0]',                          \n",
      "                                                                  'Transformer-4-FeedForward-Norm[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " Transformer-5-MultiHeadSelfAtt  (None, None, 768)   0           ['Transformer-5-MultiHeadSelfAtte\n",
      " ention-Dropout (Dropout)                                        ntion[0][0]']                    \n",
      "                                                                                                  \n",
      " Transformer-5-MultiHeadSelfAtt  (None, None, 768)   0           ['Transformer-4-FeedForward-Norm[\n",
      " ention-Add (Add)                                                0][0]',                          \n",
      "                                                                  'Transformer-5-MultiHeadSelfAtte\n",
      "                                                                 ntion-Dropout[0][0]']            \n",
      "                                                                                                  \n",
      " Transformer-5-MultiHeadSelfAtt  (None, None, 768)   1536        ['Transformer-5-MultiHeadSelfAtte\n",
      " ention-Norm (LayerNormalizatio                                  ntion-Add[0][0]']                \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " Transformer-5-FeedForward (Fee  (None, None, 768)   4722432     ['Transformer-5-MultiHeadSelfAtte\n",
      " dForward)                                                       ntion-Norm[0][0]']               \n",
      "                                                                                                  \n",
      " Transformer-5-FeedForward-Drop  (None, None, 768)   0           ['Transformer-5-FeedForward[0][0]\n",
      " out (Dropout)                                                   ']                               \n",
      "                                                                                                  \n",
      " Transformer-5-FeedForward-Add   (None, None, 768)   0           ['Transformer-5-MultiHeadSelfAtte\n",
      " (Add)                                                           ntion-Norm[0][0]',               \n",
      "                                                                  'Transformer-5-FeedForward-Dropo\n",
      "                                                                 ut[0][0]']                       \n",
      "                                                                                                  \n",
      " Transformer-5-FeedForward-Norm  (None, None, 768)   1536        ['Transformer-5-FeedForward-Add[0\n",
      "  (LayerNormalization)                                           ][0]']                           \n",
      "                                                                                                  \n",
      " Transformer-6-MultiHeadSelfAtt  (None, None, 768)   2362368     ['Transformer-5-FeedForward-Norm[\n",
      " ention (MultiHeadAttention)                                     0][0]',                          \n",
      "                                                                  'Transformer-5-FeedForward-Norm[\n",
      "                                                                 0][0]',                          \n",
      "                                                                  'Transformer-5-FeedForward-Norm[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " Transformer-6-MultiHeadSelfAtt  (None, None, 768)   0           ['Transformer-6-MultiHeadSelfAtte\n",
      " ention-Dropout (Dropout)                                        ntion[0][0]']                    \n",
      "                                                                                                  \n",
      " Transformer-6-MultiHeadSelfAtt  (None, None, 768)   0           ['Transformer-5-FeedForward-Norm[\n",
      " ention-Add (Add)                                                0][0]',                          \n",
      "                                                                  'Transformer-6-MultiHeadSelfAtte\n",
      "                                                                 ntion-Dropout[0][0]']            \n",
      "                                                                                                  \n",
      " Transformer-6-MultiHeadSelfAtt  (None, None, 768)   1536        ['Transformer-6-MultiHeadSelfAtte\n",
      " ention-Norm (LayerNormalizatio                                  ntion-Add[0][0]']                \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " Transformer-6-FeedForward (Fee  (None, None, 768)   4722432     ['Transformer-6-MultiHeadSelfAtte\n",
      " dForward)                                                       ntion-Norm[0][0]']               \n",
      "                                                                                                  \n",
      " Transformer-6-FeedForward-Drop  (None, None, 768)   0           ['Transformer-6-FeedForward[0][0]\n",
      " out (Dropout)                                                   ']                               \n",
      "                                                                                                  \n",
      " Transformer-6-FeedForward-Add   (None, None, 768)   0           ['Transformer-6-MultiHeadSelfAtte\n",
      " (Add)                                                           ntion-Norm[0][0]',               \n",
      "                                                                  'Transformer-6-FeedForward-Dropo\n",
      "                                                                 ut[0][0]']                       \n",
      "                                                                                                  \n",
      " Transformer-6-FeedForward-Norm  (None, None, 768)   1536        ['Transformer-6-FeedForward-Add[0\n",
      "  (LayerNormalization)                                           ][0]']                           \n",
      "                                                                                                  \n",
      " Transformer-7-MultiHeadSelfAtt  (None, None, 768)   2362368     ['Transformer-6-FeedForward-Norm[\n",
      " ention (MultiHeadAttention)                                     0][0]',                          \n",
      "                                                                  'Transformer-6-FeedForward-Norm[\n",
      "                                                                 0][0]',                          \n",
      "                                                                  'Transformer-6-FeedForward-Norm[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " Transformer-7-MultiHeadSelfAtt  (None, None, 768)   0           ['Transformer-7-MultiHeadSelfAtte\n",
      " ention-Dropout (Dropout)                                        ntion[0][0]']                    \n",
      "                                                                                                  \n",
      " Transformer-7-MultiHeadSelfAtt  (None, None, 768)   0           ['Transformer-6-FeedForward-Norm[\n",
      " ention-Add (Add)                                                0][0]',                          \n",
      "                                                                  'Transformer-7-MultiHeadSelfAtte\n",
      "                                                                 ntion-Dropout[0][0]']            \n",
      "                                                                                                  \n",
      " Transformer-7-MultiHeadSelfAtt  (None, None, 768)   1536        ['Transformer-7-MultiHeadSelfAtte\n",
      " ention-Norm (LayerNormalizatio                                  ntion-Add[0][0]']                \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " Transformer-7-FeedForward (Fee  (None, None, 768)   4722432     ['Transformer-7-MultiHeadSelfAtte\n",
      " dForward)                                                       ntion-Norm[0][0]']               \n",
      "                                                                                                  \n",
      " Transformer-7-FeedForward-Drop  (None, None, 768)   0           ['Transformer-7-FeedForward[0][0]\n",
      " out (Dropout)                                                   ']                               \n",
      "                                                                                                  \n",
      " Transformer-7-FeedForward-Add   (None, None, 768)   0           ['Transformer-7-MultiHeadSelfAtte\n",
      " (Add)                                                           ntion-Norm[0][0]',               \n",
      "                                                                  'Transformer-7-FeedForward-Dropo\n",
      "                                                                 ut[0][0]']                       \n",
      "                                                                                                  \n",
      " Transformer-7-FeedForward-Norm  (None, None, 768)   1536        ['Transformer-7-FeedForward-Add[0\n",
      "  (LayerNormalization)                                           ][0]']                           \n",
      "                                                                                                  \n",
      " Transformer-8-MultiHeadSelfAtt  (None, None, 768)   2362368     ['Transformer-7-FeedForward-Norm[\n",
      " ention (MultiHeadAttention)                                     0][0]',                          \n",
      "                                                                  'Transformer-7-FeedForward-Norm[\n",
      "                                                                 0][0]',                          \n",
      "                                                                  'Transformer-7-FeedForward-Norm[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " Transformer-8-MultiHeadSelfAtt  (None, None, 768)   0           ['Transformer-8-MultiHeadSelfAtte\n",
      " ention-Dropout (Dropout)                                        ntion[0][0]']                    \n",
      "                                                                                                  \n",
      " Transformer-8-MultiHeadSelfAtt  (None, None, 768)   0           ['Transformer-7-FeedForward-Norm[\n",
      " ention-Add (Add)                                                0][0]',                          \n",
      "                                                                  'Transformer-8-MultiHeadSelfAtte\n",
      "                                                                 ntion-Dropout[0][0]']            \n",
      "                                                                                                  \n",
      " Transformer-8-MultiHeadSelfAtt  (None, None, 768)   1536        ['Transformer-8-MultiHeadSelfAtte\n",
      " ention-Norm (LayerNormalizatio                                  ntion-Add[0][0]']                \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " Transformer-8-FeedForward (Fee  (None, None, 768)   4722432     ['Transformer-8-MultiHeadSelfAtte\n",
      " dForward)                                                       ntion-Norm[0][0]']               \n",
      "                                                                                                  \n",
      " Transformer-8-FeedForward-Drop  (None, None, 768)   0           ['Transformer-8-FeedForward[0][0]\n",
      " out (Dropout)                                                   ']                               \n",
      "                                                                                                  \n",
      " Transformer-8-FeedForward-Add   (None, None, 768)   0           ['Transformer-8-MultiHeadSelfAtte\n",
      " (Add)                                                           ntion-Norm[0][0]',               \n",
      "                                                                  'Transformer-8-FeedForward-Dropo\n",
      "                                                                 ut[0][0]']                       \n",
      "                                                                                                  \n",
      " Transformer-8-FeedForward-Norm  (None, None, 768)   1536        ['Transformer-8-FeedForward-Add[0\n",
      "  (LayerNormalization)                                           ][0]']                           \n",
      "                                                                                                  \n",
      " Transformer-9-MultiHeadSelfAtt  (None, None, 768)   2362368     ['Transformer-8-FeedForward-Norm[\n",
      " ention (MultiHeadAttention)                                     0][0]',                          \n",
      "                                                                  'Transformer-8-FeedForward-Norm[\n",
      "                                                                 0][0]',                          \n",
      "                                                                  'Transformer-8-FeedForward-Norm[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " Transformer-9-MultiHeadSelfAtt  (None, None, 768)   0           ['Transformer-9-MultiHeadSelfAtte\n",
      " ention-Dropout (Dropout)                                        ntion[0][0]']                    \n",
      "                                                                                                  \n",
      " Transformer-9-MultiHeadSelfAtt  (None, None, 768)   0           ['Transformer-8-FeedForward-Norm[\n",
      " ention-Add (Add)                                                0][0]',                          \n",
      "                                                                  'Transformer-9-MultiHeadSelfAtte\n",
      "                                                                 ntion-Dropout[0][0]']            \n",
      "                                                                                                  \n",
      " Transformer-9-MultiHeadSelfAtt  (None, None, 768)   1536        ['Transformer-9-MultiHeadSelfAtte\n",
      " ention-Norm (LayerNormalizatio                                  ntion-Add[0][0]']                \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " Transformer-9-FeedForward (Fee  (None, None, 768)   4722432     ['Transformer-9-MultiHeadSelfAtte\n",
      " dForward)                                                       ntion-Norm[0][0]']               \n",
      "                                                                                                  \n",
      " Transformer-9-FeedForward-Drop  (None, None, 768)   0           ['Transformer-9-FeedForward[0][0]\n",
      " out (Dropout)                                                   ']                               \n",
      "                                                                                                  \n",
      " Transformer-9-FeedForward-Add   (None, None, 768)   0           ['Transformer-9-MultiHeadSelfAtte\n",
      " (Add)                                                           ntion-Norm[0][0]',               \n",
      "                                                                  'Transformer-9-FeedForward-Dropo\n",
      "                                                                 ut[0][0]']                       \n",
      "                                                                                                  \n",
      " Transformer-9-FeedForward-Norm  (None, None, 768)   1536        ['Transformer-9-FeedForward-Add[0\n",
      "  (LayerNormalization)                                           ][0]']                           \n",
      "                                                                                                  \n",
      " Transformer-10-MultiHeadSelfAt  (None, None, 768)   2362368     ['Transformer-9-FeedForward-Norm[\n",
      " tention (MultiHeadAttention)                                    0][0]',                          \n",
      "                                                                  'Transformer-9-FeedForward-Norm[\n",
      "                                                                 0][0]',                          \n",
      "                                                                  'Transformer-9-FeedForward-Norm[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " Transformer-10-MultiHeadSelfAt  (None, None, 768)   0           ['Transformer-10-MultiHeadSelfAtt\n",
      " tention-Dropout (Dropout)                                       ention[0][0]']                   \n",
      "                                                                                                  \n",
      " Transformer-10-MultiHeadSelfAt  (None, None, 768)   0           ['Transformer-9-FeedForward-Norm[\n",
      " tention-Add (Add)                                               0][0]',                          \n",
      "                                                                  'Transformer-10-MultiHeadSelfAtt\n",
      "                                                                 ention-Dropout[0][0]']           \n",
      "                                                                                                  \n",
      " Transformer-10-MultiHeadSelfAt  (None, None, 768)   1536        ['Transformer-10-MultiHeadSelfAtt\n",
      " tention-Norm (LayerNormalizati                                  ention-Add[0][0]']               \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Transformer-10-FeedForward (Fe  (None, None, 768)   4722432     ['Transformer-10-MultiHeadSelfAtt\n",
      " edForward)                                                      ention-Norm[0][0]']              \n",
      "                                                                                                  \n",
      " Transformer-10-FeedForward-Dro  (None, None, 768)   0           ['Transformer-10-FeedForward[0][0\n",
      " pout (Dropout)                                                  ]']                              \n",
      "                                                                                                  \n",
      " Transformer-10-FeedForward-Add  (None, None, 768)   0           ['Transformer-10-MultiHeadSelfAtt\n",
      "  (Add)                                                          ention-Norm[0][0]',              \n",
      "                                                                  'Transformer-10-FeedForward-Drop\n",
      "                                                                 out[0][0]']                      \n",
      "                                                                                                  \n",
      " Transformer-10-FeedForward-Nor  (None, None, 768)   1536        ['Transformer-10-FeedForward-Add[\n",
      " m (LayerNormalization)                                          0][0]']                          \n",
      "                                                                                                  \n",
      " Transformer-11-MultiHeadSelfAt  (None, None, 768)   2362368     ['Transformer-10-FeedForward-Norm\n",
      " tention (MultiHeadAttention)                                    [0][0]',                         \n",
      "                                                                  'Transformer-10-FeedForward-Norm\n",
      "                                                                 [0][0]',                         \n",
      "                                                                  'Transformer-10-FeedForward-Norm\n",
      "                                                                 [0][0]']                         \n",
      "                                                                                                  \n",
      " Transformer-11-MultiHeadSelfAt  (None, None, 768)   0           ['Transformer-11-MultiHeadSelfAtt\n",
      " tention-Dropout (Dropout)                                       ention[0][0]']                   \n",
      "                                                                                                  \n",
      " Transformer-11-MultiHeadSelfAt  (None, None, 768)   0           ['Transformer-10-FeedForward-Norm\n",
      " tention-Add (Add)                                               [0][0]',                         \n",
      "                                                                  'Transformer-11-MultiHeadSelfAtt\n",
      "                                                                 ention-Dropout[0][0]']           \n",
      "                                                                                                  \n",
      " Transformer-11-MultiHeadSelfAt  (None, None, 768)   1536        ['Transformer-11-MultiHeadSelfAtt\n",
      " tention-Norm (LayerNormalizati                                  ention-Add[0][0]']               \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Transformer-11-FeedForward (Fe  (None, None, 768)   4722432     ['Transformer-11-MultiHeadSelfAtt\n",
      " edForward)                                                      ention-Norm[0][0]']              \n",
      "                                                                                                  \n",
      " Transformer-11-FeedForward-Dro  (None, None, 768)   0           ['Transformer-11-FeedForward[0][0\n",
      " pout (Dropout)                                                  ]']                              \n",
      "                                                                                                  \n",
      " Transformer-11-FeedForward-Add  (None, None, 768)   0           ['Transformer-11-MultiHeadSelfAtt\n",
      "  (Add)                                                          ention-Norm[0][0]',              \n",
      "                                                                  'Transformer-11-FeedForward-Drop\n",
      "                                                                 out[0][0]']                      \n",
      "                                                                                                  \n",
      " Transformer-11-FeedForward-Nor  (None, None, 768)   1536        ['Transformer-11-FeedForward-Add[\n",
      " m (LayerNormalization)                                          0][0]']                          \n",
      "                                                                                                  \n",
      " efficient_global_pointer (Effi  (None, 7, None, Non  100238     ['Transformer-11-FeedForward-Norm\n",
      " cientGlobalPointer)            e)                               [0][0]']                         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 108,991,886\n",
      "Trainable params: 108,991,886\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#! -*- coding: utf-8 -*-\n",
    "# 用GlobalPointer做中文命名实体识别\n",
    "\n",
    "import os\n",
    "os.environ[\"TF_KERAS\"] = \"1\" # use tf 2.7 keras\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from bert4keras.backend import keras, K\n",
    "from bert4keras.backend import multilabel_categorical_crossentropy\n",
    "#from bert4keras.layers import GlobalPointer\n",
    "from bert4keras.layers import EfficientGlobalPointer as GlobalPointer\n",
    "from bert4keras.models import build_transformer_model\n",
    "from bert4keras.tokenizers import Tokenizer\n",
    "from bert4keras.optimizers import Adam, extend_with_exponential_moving_average\n",
    "from bert4keras.snippets import sequence_padding, DataGenerator\n",
    "from bert4keras.snippets import open, to_array\n",
    "from keras.models import Model\n",
    "from tqdm import tqdm\n",
    "\n",
    "maxlen = 512\n",
    "epochs = 5\n",
    "batch_size = 8\n",
    "learning_rate = 2e-5\n",
    "categories = set()\n",
    "\n",
    "# bert配置\n",
    "config_path = '/kaggle/input/google_bert/tensorflow2/bert_base_uncased/1/bert_config.json'\n",
    "checkpoint_path = None #'/kaggle/input/google_bert/tensorflow2/bert_base_uncased/1/bert_model.ckpt'\n",
    "dict_path = '/kaggle/input/google_bert/tensorflow2/bert_base_uncased/1/vocab.txt'\n",
    "\n",
    "def load_data(filename):\n",
    "    \"\"\"加载数据\n",
    "    单条格式：[text, (start, end, label), (start, end, label), ...]，\n",
    "              意味着text[start:end + 1]是类型为label的实体。\n",
    "    \"\"\"\n",
    "    D = []\n",
    "    for d in json.load(open(filename)):\n",
    "        D.append([d['text']])\n",
    "        for e in d['entities']:\n",
    "            start, end, label = e['start_idx'], e['end_idx'], e['type']\n",
    "            if start <= end:\n",
    "                D[-1].append((start, end, label))\n",
    "            categories.add(label)\n",
    "    return D\n",
    "\n",
    "\n",
    "# 标注数据\n",
    "train_data = load_data('./train.json')\n",
    "valid_data = load_data('./dev.json')\n",
    "categories = list(sorted(categories))\n",
    "\n",
    "print(\"labels: \", categories)\n",
    "# labels:  ['EMAIL', 'ID_NUM', 'NAME_STUDENT', 'PHONE_NUM', 'STREET_ADDRESS', 'URL_PERSONAL', 'USERNAME']\n",
    "\n",
    "\n",
    "# 建立分词器\n",
    "tokenizer = Tokenizer(dict_path, do_lower_case=True)\n",
    "\n",
    "\n",
    "class data_generator(DataGenerator):\n",
    "    \"\"\"数据生成器\n",
    "    \"\"\"\n",
    "    def __iter__(self, random=False):\n",
    "        batch_token_ids, batch_segment_ids, batch_labels = [], [], []\n",
    "        for is_end, d in self.sample(random):\n",
    "            tokens = tokenizer.tokenize(d[0], maxlen=maxlen)\n",
    "            mapping = tokenizer.rematch(d[0], tokens)\n",
    "            start_mapping = {j[0]: i for i, j in enumerate(mapping) if j}\n",
    "            end_mapping = {j[-1]: i for i, j in enumerate(mapping) if j}\n",
    "            token_ids = tokenizer.tokens_to_ids(tokens)\n",
    "            segment_ids = [0] * len(token_ids)\n",
    "            labels = np.zeros((len(categories), maxlen, maxlen))\n",
    "            for start, end, label in d[1:]:\n",
    "                if start in start_mapping and end in end_mapping:\n",
    "                    start = start_mapping[start]\n",
    "                    end = end_mapping[end]\n",
    "                    label = categories.index(label)\n",
    "                    labels[label, start, end] = 1\n",
    "            batch_token_ids.append(token_ids)\n",
    "            batch_segment_ids.append(segment_ids)\n",
    "            batch_labels.append(labels[:, :len(token_ids), :len(token_ids)])\n",
    "            if len(batch_token_ids) == self.batch_size or is_end:\n",
    "                batch_token_ids = sequence_padding(batch_token_ids)\n",
    "                batch_segment_ids = sequence_padding(batch_segment_ids)\n",
    "                batch_labels = sequence_padding(batch_labels, seq_dims=3)\n",
    "                yield [batch_token_ids, batch_segment_ids], batch_labels\n",
    "                batch_token_ids, batch_segment_ids, batch_labels = [], [], []\n",
    "\n",
    "\n",
    "def global_pointer_crossentropy(y_true, y_pred):\n",
    "    \"\"\"给GlobalPointer设计的交叉熵\n",
    "    \"\"\"\n",
    "    bh = K.prod(K.shape(y_pred)[:2])\n",
    "    y_true = K.reshape(y_true, (bh, -1))\n",
    "    y_pred = K.reshape(y_pred, (bh, -1))\n",
    "    return K.mean(multilabel_categorical_crossentropy(y_true, y_pred))\n",
    "\n",
    "\n",
    "def global_pointer_f1_score(y_true, y_pred):\n",
    "    \"\"\"给GlobalPointer设计的F1\n",
    "    \"\"\"\n",
    "    y_pred = K.cast(K.greater(y_pred, 0), K.floatx())\n",
    "    return 2 * K.sum(y_true * y_pred) / K.sum(y_true + y_pred)\n",
    "\n",
    "\n",
    "model = build_transformer_model(config_path, checkpoint_path)\n",
    "output = GlobalPointer(len(categories), 64)(model.output)\n",
    "\n",
    "AdamEMA = extend_with_exponential_moving_average(Adam, name='AdamEMA')\n",
    "optimizer = AdamEMA(learning_rate=learning_rate)\n",
    "\n",
    "model = Model(model.input, output)\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    loss=global_pointer_crossentropy,\n",
    "    optimizer=optimizer, #Adam(learning_rate),\n",
    "    #optimizer=Adam(learning_rate),\n",
    "    metrics=[global_pointer_f1_score]\n",
    ")\n",
    "\n",
    "\n",
    "class NamedEntityRecognizer(object):\n",
    "    \"\"\"命名实体识别器\n",
    "    \"\"\"\n",
    "    def recognize(self, text, threshold=0):\n",
    "        tokens = tokenizer.tokenize(text, maxlen=512)\n",
    "        mapping = tokenizer.rematch(text, tokens)\n",
    "        token_ids = tokenizer.tokens_to_ids(tokens)\n",
    "        segment_ids = [0] * len(token_ids)\n",
    "        token_ids, segment_ids = to_array([token_ids], [segment_ids])\n",
    "        scores = model.predict([token_ids, segment_ids])[0]\n",
    "        scores[:, [0, -1]] -= np.inf\n",
    "        scores[:, :, [0, -1]] -= np.inf\n",
    "        entities = []\n",
    "        for l, start, end in zip(*np.where(scores > threshold)):\n",
    "            entities.append(\n",
    "                (mapping[start][0], mapping[end][-1], categories[l])\n",
    "            )\n",
    "        return entities\n",
    "\n",
    "\n",
    "NER = NamedEntityRecognizer()\n",
    "\n",
    "\n",
    "def evaluate(data):\n",
    "    \"\"\"评测函数\n",
    "    \"\"\"\n",
    "    X, Y, Z = 1e-10, 1e-10, 1e-10\n",
    "    for d in tqdm(data, ncols=100):\n",
    "        R = set(NER.recognize(d[0]))\n",
    "        T = set([tuple(i) for i in d[1:]])\n",
    "        X += len(R & T)\n",
    "        Y += len(R)\n",
    "        Z += len(T)\n",
    "    f1, precision, recall = 2 * X / (Y + Z), X / Y, X / Z\n",
    "    return f1, precision, recall\n",
    "\n",
    "\n",
    "class Evaluator(keras.callbacks.Callback):\n",
    "    \"\"\"评估与保存\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.best_val_f1 = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        f1, precision, recall = evaluate(valid_data)\n",
    "        # 保存最优\n",
    "        if f1 >= self.best_val_f1:\n",
    "            self.best_val_f1 = f1\n",
    "            model.save_weights('./pii_gp_best_f1.h5')\n",
    "        print(\n",
    "            'valid:  f1: %.5f, precision: %.5f, recall: %.5f, best f1: %.5f\\n' %\n",
    "            (f1, precision, recall, self.best_val_f1)\n",
    "        )\n",
    "\n",
    "\n",
    "def predict_to_file(in_file, out_file):\n",
    "    \"\"\"预测到文件\n",
    "    \"\"\"\n",
    "    data = json.load(open(in_file))\n",
    "\n",
    "    document = \"\"\n",
    "    last_pos = 0\n",
    "    D = []\n",
    "\n",
    "    for d in tqdm(data, ncols=100):\n",
    "\n",
    "        if document != d['document']:\n",
    "            document = d['document']\n",
    "            last_pos = 0\n",
    "\n",
    "        # 初始化 BIO 标记\n",
    "        label = ['O']*len(d['tokens'])\n",
    "\n",
    "        # 识别\n",
    "        entities = NER.recognize(d['text'])\n",
    "        for e in entities:\n",
    "            d['entities'].append({\n",
    "                'start_idx': e[0],\n",
    "                'end_idx': e[1],\n",
    "                'type': e[2]\n",
    "            })\n",
    "\n",
    "            # 生成 BIO标记, 依据 原始 tokens\n",
    "            pos = last = 0\n",
    "            for n, x in enumerate(d['tokens']):\n",
    "                if pos >= e[0] and pos <= e[1]+1:\n",
    "                    if last==0:\n",
    "                        label[n] = 'B-'+e[2]\n",
    "                        last += 1\n",
    "                    else:\n",
    "                        label[n] = 'I-'+e[2]\n",
    "                    D.append((document, last_pos+n, label[n]))\n",
    "                else:\n",
    "                    last = 0\n",
    "\n",
    "                pos += len(x)\n",
    "\n",
    "                if pos > e[1]:\n",
    "                    break\n",
    "\n",
    "        d['labels'] = label\n",
    "\n",
    "        last_pos += len(d['tokens'])\n",
    "\n",
    "    # 保存json格式\n",
    "    json.dump(\n",
    "        data,\n",
    "        open(\"output.json\", 'w', encoding='utf-8'),\n",
    "        indent=4,\n",
    "        ensure_ascii=False\n",
    "    )\n",
    "\n",
    "    with open(out_file, \"w\") as f:\n",
    "        f.write(\"row_id,document,token,label\\n\")\n",
    "        for n, x in enumerate(D):\n",
    "            f.write(f\"{n},{x[0]},{x[1]},{x[2]}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d1b304",
   "metadata": {
    "papermill": {
     "duration": 0.103964,
     "end_time": "2024-01-25T13:47:31.077251",
     "exception": false,
     "start_time": "2024-01-25T13:47:30.973287",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "823e0e54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-25T13:47:31.205290Z",
     "iopub.status.busy": "2024-01-25T13:47:31.204932Z",
     "iopub.status.idle": "2024-01-25T13:56:27.525644Z",
     "shell.execute_reply": "2024-01-25T13:56:27.524604Z"
    },
    "papermill": {
     "duration": 536.38672,
     "end_time": "2024-01-25T13:56:27.527763",
     "exception": false,
     "start_time": "2024-01-25T13:47:31.141043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.0370 - global_pointer_f1_score: 0.9628"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████| 224/224 [00:33<00:00,  6.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid:  f1: 0.98705, precision: 0.97721, recall: 0.99709, best f1: 0.98705\n",
      "\n",
      "112/112 [==============================] - 145s 960ms/step - loss: 0.0370 - global_pointer_f1_score: 0.9628\n",
      "Epoch 2/5\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.0124 - global_pointer_f1_score: 0.9906"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████| 224/224 [00:25<00:00,  8.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid:  f1: 0.98990, precision: 0.98281, recall: 0.99709, best f1: 0.98990\n",
      "\n",
      "112/112 [==============================] - 99s 887ms/step - loss: 0.0124 - global_pointer_f1_score: 0.9906\n",
      "Epoch 3/5\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.0083 - global_pointer_f1_score: 0.9911"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████| 224/224 [00:23<00:00,  9.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid:  f1: 0.98844, precision: 0.98276, recall: 0.99419, best f1: 0.98990\n",
      "\n",
      "112/112 [==============================] - 96s 862ms/step - loss: 0.0083 - global_pointer_f1_score: 0.9911\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - ETA: 0s - loss: 0.0086 - global_pointer_f1_score: 0.9951"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████| 224/224 [00:23<00:00,  9.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid:  f1: 0.98705, precision: 0.97721, recall: 0.99709, best f1: 0.98990\n",
      "\n",
      "112/112 [==============================] - 96s 862ms/step - loss: 0.0086 - global_pointer_f1_score: 0.9951\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - ETA: 0s - loss: 0.0065 - global_pointer_f1_score: 0.9959"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████| 224/224 [00:23<00:00,  9.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid:  f1: 0.98847, precision: 0.98000, recall: 0.99709, best f1: 0.98990\n",
      "\n",
      "112/112 [==============================] - 96s 857ms/step - loss: 0.0065 - global_pointer_f1_score: 0.9959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7df444da0b80>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练\n",
    "\n",
    "evaluator = Evaluator()\n",
    "train_generator = data_generator(train_data, batch_size)\n",
    "\n",
    "model.load_weights('/kaggle/input/google_bert/tensorflow2/bert_base_uncased_pii_43k_noblank/1/pii_gp_best_f1_0.92476.h5')\n",
    "\n",
    "model.fit(\n",
    "    train_generator.forfit(),\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=epochs,\n",
    "    callbacks=[evaluator]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883b8094",
   "metadata": {
    "papermill": {
     "duration": 0.17119,
     "end_time": "2024-01-25T13:56:27.871709",
     "exception": false,
     "start_time": "2024-01-25T13:56:27.700519",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Generate result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e73d2f8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-25T13:56:28.215741Z",
     "iopub.status.busy": "2024-01-25T13:56:28.215112Z",
     "iopub.status.idle": "2024-01-25T13:56:31.172464Z",
     "shell.execute_reply": "2024-01-25T13:56:31.171439Z"
    },
    "papermill": {
     "duration": 3.131826,
     "end_time": "2024-01-25T13:56:31.174536",
     "exception": false,
     "start_time": "2024-01-25T13:56:28.042710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 24/24 [00:02<00:00, 10.39it/s]\n"
     ]
    }
   ],
   "source": [
    "# 推理生成结果\n",
    "\n",
    "model.load_weights('pii_gp_best_f1.h5')\n",
    "predict_to_file('test.json', 'submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 7500999,
     "sourceId": 66653,
     "sourceType": "competition"
    },
    {
     "datasetId": 4346910,
     "sourceId": 7467717,
     "sourceType": "datasetVersion"
    },
    {
     "modelInstanceId": 5505,
     "sourceId": 7026,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 5390,
     "sourceId": 6871,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30635,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 647.887233,
   "end_time": "2024-01-25T13:56:34.594015",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-25T13:45:46.706782",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
